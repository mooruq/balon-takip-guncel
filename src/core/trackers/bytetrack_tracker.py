import cv2
import time
import torch
import threading
import numpy as np
from PyQt5.QtCore import QThread
import os
import sys

# Config ve logger imports
from src.utils.config import config
from src.utils.logger import logger

# Kamera kalibrasyonu import
try:
    from src.utils.camera_calibration_service import CameraCalibrationService, find_latest_calibration_file
    CALIBRATION_AVAILABLE = True
except ImportError:
    CALIBRATION_AVAILABLE = False
    logger.warning("âš ï¸ Kamera kalibrasyon servisi bulunamadÄ±, lens distorsiyonu dÃ¼zeltilmeyecek")

# ByteTrack import kontrolÃ¼
try:
    # ByteTrack gerÃ§ek implementasyonu iÃ§in path ekleme
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', '..', 'OC_SORT'))
    from OC_SORT.trackers.byte_tracker.byte_tracker import BYTETracker, STrack
    from OC_SORT.trackers.byte_tracker.basetrack import TrackState
except ImportError as e:
    try:
        # Alternatif olarak OC_SORT direkten import et
        from OC_SORT.trackers.byte_tracker.byte_tracker_public import BYTETracker, STrack
        from OC_SORT.trackers.byte_tracker.basetrack import TrackState
    except ImportError as e2:
        raise ImportError("ByteTracker import edilemedi. LÃ¼tfen OC_SORT kurulumunu kontrol edin.")

from ultralytics import YOLO
from src.utils.visuals import draw_annotations, assign_class_to_track, draw_overlay_info

# ByteTracker parametreleri iÃ§in arguments class
class Args:
    def __init__(self):
        # Config'den parametreleri al
        self.track_thresh = config.track_thresh  # High confidence threshold
        self.track_buffer = config.track_buffer  # Buffer size
        self.match_thresh = config.match_thresh  # Association threshold
        self.mot20 = False       # MOT20 dataset flag
        
        # Performans iÃ§in optimize edilmiÅŸ parametreler
        self.min_box_area = 100  # Minimum detection area
        self.aspect_ratio_thresh = 1.6  # Aspect ratio threshold
        
        logger.debug(f"ByteTracker Args: thresh={self.track_thresh}, buffer={self.track_buffer}, match={self.match_thresh}")

stop_event = threading.Event()

def stop_bytetrack_tracking():
    stop_event.set()

def reset_bytetrack_tracking():
    stop_event.clear()

def run_bytetrack_tracking(source, model_path, video_display, confidence_threshold=0.3):
    """Original tracking function - model dosyasÄ±ndan yÃ¼kleyerek"""
    reset_bytetrack_tracking()
    
    logger.info(f"ğŸ”„ ByteTracker baÅŸlatÄ±lÄ±yor - Model: {model_path}")
    model = YOLO(model_path)
    _run_bytetrack_with_loaded_model(source, model, video_display, confidence_threshold)


def run_bytetrack_with_model(source, loaded_model, video_display, confidence_threshold=0.3, motor_controller=None):
    """Preloaded model ile hÄ±zlÄ± baÅŸlatma - model yÃ¼kleme sÃ¼resini atlar"""
    reset_bytetrack_tracking()
    
    logger.info(f"âš¡ ByteTracker hÄ±zlÄ± baÅŸlatma - Kamera: {source}, Confidence: {confidence_threshold}")
    _run_bytetrack_with_loaded_model(source, loaded_model, video_display, confidence_threshold, motor_controller)


def _run_bytetrack_with_loaded_model(source, model, video_display, confidence_threshold=0.3, motor_controller=None):
    """Ortak tracking fonksiyonu - loaded model ile Ã§alÄ±ÅŸÄ±r"""
    labels = model.names
    logger.info(f"ğŸ“¹ Kamera baÄŸlantÄ±sÄ± aÃ§Ä±lÄ±yor: {source}")
    
    # Kamera kalibrasyonu setup
    calibration_service = None
    if CALIBRATION_AVAILABLE:
        calibration_service = CameraCalibrationService()
        # En son kalibrasyon dosyasÄ±nÄ± otomatik bul ve yÃ¼kle - Ã¶nce data klasÃ¶rÃ¼nde ara
        calibration_file = find_latest_calibration_file("data") or find_latest_calibration_file(".")
        if calibration_file:
            if calibration_service.load_calibration(calibration_file):
                cal_info = calibration_service.get_calibration_info()
                if cal_info:
                    logger.info(f"ğŸ“· Kamera kalibrasyonu yÃ¼klendi - Error: {cal_info['calibration_error']:.3f}px")
                    logger.info(f"ğŸ“· Kalibrasyon dosyasÄ±: {calibration_file}")
                else:
                    logger.warning("âš ï¸ Kalibrasyon bilgisi alÄ±namadÄ±")
                    calibration_service = None
            else:
                logger.warning("âš ï¸ Kalibrasyon dosyasÄ± yÃ¼klenemedi")
                calibration_service = None
        else:
            logger.info("â„¹ï¸ Kalibrasyon dosyasÄ± bulunamadÄ± - ham kamera gÃ¶rÃ¼ntÃ¼sÃ¼ kullanÄ±lacak")
            calibration_service = None
    
    # Kamera aÃ§ma - backend config'e gÃ¶re
    if config.use_directshow_backend and isinstance(source, int):
        cap = cv2.VideoCapture(source, cv2.CAP_DSHOW)
    else:
        cap = cv2.VideoCapture(source)

    if not cap.isOpened():
        logger.warning(f"âš ï¸ DSHOW backend baÅŸarÄ±sÄ±z, alternatif denenecek: {source}")
        # DSHOW baÅŸarÄ±sÄ±zsa alternatif dene
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            logger.error(f"âŒ Kamera aÃ§Ä±lamadÄ±: {source}")
            return

    video_fps = cap.get(cv2.CAP_PROP_FPS) or config.camera_fps
    logger.info(f"âœ… Kamera baÅŸarÄ±yla aÃ§Ä±ldÄ± - FPS: {video_fps}")
    frame_count = 0
    
    # ByteTracker initialize
    args = Args()
    args.track_thresh = confidence_threshold
    byte_tracker = BYTETracker(args, frame_rate=int(video_fps))
    
    # Frame skipping ve buffering iÃ§in
    frame_skip = max(1, int(video_fps / 30))  # 30 FPS'e normalize et
    
    # Tracking history for smoothing
    track_history = {}
    max_history = 10
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            break

        frame_count += 1
        
        # Frame skipping - hÄ±zlÄ± hareketlerde daha sÄ±k iÅŸle
        if frame_count % frame_skip != 0:
            continue

        start = time.time()
        
        # Kamera kalibrasyonu uygulanmasÄ± (lens distorsiyonu dÃ¼zeltme)
        original_frame = frame.copy()  # Orijinal frame'i sakla
        if calibration_service and calibration_service.is_calibrated():
            frame = calibration_service.undistort_frame(frame)
        
        # YOLO detection (tracking olmadan, sadece detection)
        results = model(
            source=frame,
            verbose=False,
            conf=confidence_threshold,
            save=False,
            stream=False
        )[0]

        # YOLO sonuÃ§larÄ±nÄ± ByteTracker formatÄ±na Ã§evir
        detections = []
        if results.boxes is not None:
            boxes = results.boxes.xyxy.cpu().numpy()  # x1, y1, x2, y2
            scores = results.boxes.conf.cpu().numpy()
            
            # Filtreleme: minimum area ve aspect ratio
            for i, (box, score) in enumerate(zip(boxes, scores)):
                x1, y1, x2, y2 = box
                w, h = x2 - x1, y2 - y1
                
                # Minimum alan kontrolÃ¼
                if w * h < byte_tracker.args.min_box_area:
                    continue
                    
                # Aspect ratio kontrolÃ¼ (Ã§ok uzun/ince olmayan nesneler)
                aspect_ratio = max(w/h, h/w) if min(w, h) > 0 else float('inf')
                if aspect_ratio > byte_tracker.args.aspect_ratio_thresh:
                    continue
                
                detections.append([x1, y1, x2, y2, score])

        # ByteTracker update - koordinat problemi Ã§Ã¶zÃ¼mÃ¼
        if len(detections) > 0:
            detections = np.array(detections)
            # ByteTracker iÃ§in doÄŸru format: img_info = (height, width), img_size = (target_width, target_height)
            # Scaling'i devre dÄ±ÅŸÄ± bÄ±rakmak iÃ§in img_size = frame boyutu yapalÄ±m
            img_info = (frame.shape[0], frame.shape[1])  # height, width (orijinal)
            img_size = (frame.shape[1], frame.shape[0])  # width, height (aynÄ± boyut = scale 1.0)
            
            online_targets = byte_tracker.update(detections, img_info, img_size)
        else:
            # BoÅŸ detection durumunda da tracker'Ä± gÃ¼ncelle
            online_targets = byte_tracker.update(np.empty((0, 5)), 
                                               (frame.shape[0], frame.shape[1]),
                                               (frame.shape[1], frame.shape[0]))

        # Tracking sonuÃ§larÄ±nÄ± Ã§iz ve motor kontrolÃ¼ iÃ§in detection listesi hazÄ±rla
        object_count = 0
        detection_list = []
        
        for track in online_targets:
            track_id = track.track_id
            
            # ByteTracker koordinatlarÄ±nÄ± debug et
            tlbr_coords = track.tlbr.astype(int)
            x1, y1, x2, y2 = tlbr_coords
            
            # KoordinatlarÄ± kontrol et ve dÃ¼zelt
            x1 = max(0, min(x1, frame.shape[1]))
            y1 = max(0, min(y1, frame.shape[0]))
            x2 = max(0, min(x2, frame.shape[1]))
            y2 = max(0, min(y2, frame.shape[0]))
            
            # GeÃ§ersiz koordinatlarÄ± atla
            if x2 <= x1 or y2 <= y1:
                continue
            
            # Balonun mevcut merkezi
            center_x = (x1 + x2) // 2
            center_y = (y1 + y2) // 2
            
            # Tracking history gÃ¼ncelle
            if track_id not in track_history:
                track_history[track_id] = []
            track_history[track_id].append((center_x, center_y))
            
            # History boyutunu sÄ±nÄ±rla
            if len(track_history[track_id]) > max_history:
                track_history[track_id] = track_history[track_id][-max_history:]

            
            # Kalman filter FUTURE prediction - velocity kullanarak gelecek tahmini
            pred_x, pred_y = center_x, center_y  # VarsayÄ±lan olarak mevcut merkez
            
            if hasattr(track, 'mean') and track.mean is not None and len(track.mean) >= 6:
                # Kalman state: [center_x, center_y, aspect_ratio, height, vx, vy, va, vh]
                current_x = track.mean[0]  # Mevcut x
                current_y = track.mean[1]  # Mevcut y
                velocity_x = track.mean[4] if len(track.mean) > 4 else 0  # x hÄ±zÄ±
                velocity_y = track.mean[5] if len(track.mean) > 5 else 0  # y hÄ±zÄ±
                
                # FUTURE prediction = mevcut konum + velocity * 2 (2 frame ahead iÃ§in daha yakÄ±n tahmin)
                prediction_frames = 2  # 2 frame ileri tahmin
                future_x = int(current_x + velocity_x * prediction_frames)
                future_y = int(current_y + velocity_y * prediction_frames)
                
                # Future prediction'Ä± makul sÄ±nÄ±rlar iÃ§indeyse kullan
                if (0 <= future_x < frame.shape[1] and 
                    0 <= future_y < frame.shape[0]):
                    pred_x, pred_y = future_x, future_y
                else:
                    # SÄ±nÄ±r dÄ±ÅŸÄ±ndaysa daha kÄ±sa prediction yaparak hesapla
                    pred_x = int(current_x + velocity_x * 1.0)  # 1.0 frame ahead
                    pred_y = int(current_y + velocity_y * 1.0)  # 1.0 frame ahead
                    pred_x = max(0, min(pred_x, frame.shape[1] - 1))
                    pred_y = max(0, min(pred_y, frame.shape[0] - 1))
            
            # Kalite skoru gÃ¶ster
            score_text = f"S:{track.score:.2f}" if hasattr(track, 'score') else ""
            label_text = f"ID:{track_id} {score_text}"
            
            draw_annotations(frame, x1, y1, x2, y2, track_id, pred_x, pred_y, label_text)
            object_count += 1
            
            # Motor kontrol sistemi iÃ§in detection ekle
            detection_list.append([x1, y1, x2 - x1, y2 - y1, track.score if hasattr(track, 'score') else 0.8, 
                                 pred_x, pred_y, track_id])
            
            # Trajectory Ã§iz (son 5 point) - daha ince Ã§izgi
            if len(track_history[track_id]) > 1:
                points = track_history[track_id][-5:]
                for i in range(1, len(points)):
                    cv2.line(frame, points[i-1], points[i], (0, 200, 0), 1)  # Daha ince (1 pixel) ve daha koyu yeÅŸil

        end = time.time()
        frame_time = end - start
        fps = 1 / frame_time if frame_time > 0 else 0

        # Tracking bilgileri
        tracked_count = len([t for t in byte_tracker.tracked_stracks if t.is_activated])
        lost_count = len(byte_tracker.lost_stracks)
        
        # Kalibrasyon durumu iÃ§in algo_name'e ekle
        algo_name = f"ByteTrack+ (T:{tracked_count} L:{lost_count})"
        if calibration_service and calibration_service.is_calibrated():
            cal_error = calibration_service.calibration_error
            algo_name += f" [CAL:{cal_error:.2f}px]"
        else:
            algo_name += " [RAW]"
        
        draw_overlay_info(
            frame, fps, frame_time * 1000, object_count,
            algo_name=algo_name,
            frame_number=frame_count
        )
        
        # Motor kontrol sistemi gÃ¼ncelleme
        if motor_controller and detection_list:
            try:
                motor_controller.set_detections(detection_list)
            except Exception as e:
                logger.debug(f"Motor controller gÃ¼ncelleme hatasÄ±: {e}")

        resized_frame = cv2.resize(frame, (1280, 720))

        if video_display:
            video_display.update_frame(resized_frame)
            if isinstance(source, str):
                QThread.msleep(int(1000 / video_fps / frame_skip))
        else:
            cv2.imshow("Balon Takibi - ByteTrack+", resized_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    cap.release()
    logger.info("ğŸ”š ByteTracker tracking sonlandÄ±rÄ±ldÄ±")
    if not video_display:
        cv2.destroyAllWindows() 